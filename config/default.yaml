init_points: 10
steps: 10 # â‰¤ 100
K: 0.1
sampling: random

hidden_size: 128
linear_size: 128 # used when num_lin_layers > 1
num_rnn_layers: 2
num_lin_layers: 2
nonlinearity_hidden: tanh # nonlinearity for hidden layers
nonlinearity_lin: tanh # nonlinearity for linear layers

batch_size: 16
seq_length: 5 # must not be too small compared to steps
every_n_step: 1 # useful for a lot of steps?
val_reg_preds: 5
loss: msd
optimizer: adam
acc_threshold: 1.0e-4
lr: 1.0e-5
precision: bf16-mixed

shuffle_trajectories: true # makes sense for linear sampling
shuffle_within_batches: false # shuffle sequences within batches (can increase stability)
drop_last: true

rnn_type: vanillarnn # type of RNN (vanillarnn, resrnn or mgu)

gridsearch:
  batch_size: { lower: 32, upper: 512, type: int }
  lr: { lower: -6, upper: -1, type: log }
  num_rnn_layers: { lower: 1, upper: 6, type: int }
  num_lin_layers: { lower: 1, upper: 6, type: int }
  hidden_size: { lower: 32, upper: 256, type: int }
  linear_size: { lower: 32, upper: 256, type: int }
  nonlinearity_lin: { list: [tanh, elu, selu], type: choice }
